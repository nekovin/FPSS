{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daeaf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from skimage import io\n",
    "from skimage.metrics import structural_similarity, peak_signal_noise_ratio\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_patient_data(base_path):\n",
    "    print(f\"Loading data from: {base_path}\")\n",
    "    \n",
    "    # Find all TIFF files in the directory\n",
    "    files = sorted(glob.glob(os.path.join(base_path, \"*.tiff\")))\n",
    "    if not files:\n",
    "        # Try other possible extensions if no .tiff files are found\n",
    "        files = sorted(glob.glob(os.path.join(base_path, \"*.tif\")))\n",
    "    if not files:\n",
    "        files = sorted(glob.glob(os.path.join(base_path, \"*.png\")))\n",
    "    if not files:\n",
    "        files = sorted(glob.glob(os.path.join(base_path, \"*.jpg\")))\n",
    "        \n",
    "    print(f\"Found {len(files)} files\")\n",
    "    \n",
    "    # Load and preprocess images\n",
    "    oct_scans = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            img = io.imread(file)\n",
    "\n",
    "            img = img.astype(np.float32)\n",
    "            if img.max() > 1.0:\n",
    "                img = img / 255.0\n",
    "                \n",
    "            oct_scans.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file}: {e}\")\n",
    "    \n",
    "    return oct_scans\n",
    "\n",
    "\n",
    "def standard_preprocessing(oct_volume):\n",
    "    preprocessed = []\n",
    "    for img in oct_volume:\n",
    "        if img.max() > 1.0:\n",
    "            img = img / 255.0\n",
    "        \n",
    "        if len(img.shape) == 2:\n",
    "            img_with_channel = img.reshape(*img.shape, 1)\n",
    "        else:\n",
    "            img_with_channel = img\n",
    "        \n",
    "        resized = cv2.resize(img_with_channel, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "        preprocessed.append(resized)\n",
    "\n",
    "    return np.array(preprocessed)\n",
    "\n",
    "def octa_preprocessing(preprocessed_data, n_neighbours, threshold):\n",
    "    n_scans = len(preprocessed_data)\n",
    "    pairs = []\n",
    "    for i in range(n_scans - 1):\n",
    "        pairs.append(preprocessed_data[i])\n",
    "        pairs.append(preprocessed_data[i+1])\n",
    "    \n",
    "    octa_images = []\n",
    "    for i in range(0, len(pairs), n_neighbours):\n",
    "        if i+1 < len(pairs):\n",
    "            octa = compute_octa(pairs[i], pairs[i+1])\n",
    "            \n",
    "            thresholded_octa = threshold_octa(octa, pairs[i], threshold)\n",
    "            \n",
    "            octa_images.append(thresholded_octa)\n",
    "\n",
    "    return octa_images #list\n",
    "\n",
    "def compute_octa(oct1, oct2):\n",
    "\n",
    "    numerator = (oct1 - oct2)**2\n",
    "    denominator = oct1**2 + oct2**2\n",
    "    \n",
    "    epsilon = 1e-10\n",
    "    octa = numerator / (denominator + epsilon)\n",
    "    \n",
    "    return octa\n",
    "\n",
    "def threshold_octa(octa, oct, threshold):\n",
    "\n",
    "    background_mask = oct > np.percentile(oct, threshold)  # Bottom 20% of OCT values\n",
    "    \n",
    "    if np.sum(background_mask) > 0:  # Ensure we have background pixels\n",
    "        background_mean = np.mean(oct[background_mask])\n",
    "        background_std = np.std(oct[background_mask])\n",
    "        \n",
    "        threshold = background_mean + 2 * background_std\n",
    "    else:\n",
    "        # If no background pixels, use a fixed threshold\n",
    "        print(\"No background pixels found, using fixed threshold\")\n",
    "        threshold = np.percentile(oct, 1)\n",
    "    \n",
    "    signal_mask = oct > threshold\n",
    "    \n",
    "    thresholded_octa = octa * signal_mask\n",
    "    \n",
    "    return thresholded_octa\n",
    "\n",
    "\n",
    "def pair_data(preprocessed_data, octa_data, n_images_per_patient):\n",
    "    preprocessed_data = preprocessed_data[:-1]  # Remove last scan to avoid out of bounds\n",
    "\n",
    "    input_target = []\n",
    "    j = 0\n",
    "    for p, o in zip(preprocessed_data, octa_data):\n",
    "        input_target.append([p, o])\n",
    "        j += 1\n",
    "        if j >= n_images_per_patient:\n",
    "            break\n",
    "\n",
    "    return input_target\n",
    "\n",
    "def preprocessing(n_patients, n_images_per_patient, n_neighbours=2, threshold=0.65):\n",
    "    dataset = {}\n",
    "    try:\n",
    "        for i in range(1,n_patients):\n",
    "            data = load_patient_data(rf\"C:\\Datasets\\ICIP training data\\ICIP training data\\0\\RawDataQA ({i})\")\n",
    "\n",
    "            preprocessed_data = standard_preprocessing(data)\n",
    "\n",
    "            octa_data = octa_preprocessing(preprocessed_data, n_neighbours, threshold)\n",
    "            #octa_data = octa_preprocessing_n_neighbours(preprocessed_data , window_size=2)\n",
    "\n",
    "            input_target_data = pair_data(preprocessed_data, octa_data, n_images_per_patient)\n",
    "\n",
    "            dataset[i] = input_target_data\n",
    "\n",
    "        return dataset\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
