digraph {
	graph [size="239.1,239.1"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1778094214672 [label="
 (1, 1, 256, 256)" fillcolor=darkolivegreen1]
	1778094019856 [label=ConvolutionBackward0]
	1778094019616 -> 1778094019856
	1778094019616 [label=ReluBackward0]
	1778094020096 -> 1778094019616
	1778094020096 [label=NativeBatchNormBackward0]
	1778094019952 -> 1778094020096
	1778094019952 [label=ConvolutionBackward0]
	1778094020288 -> 1778094019952
	1778094020288 [label=ReluBackward0]
	1778094020480 -> 1778094020288
	1778094020480 [label=NativeBatchNormBackward0]
	1778094020576 -> 1778094020480
	1778094020576 [label=ConvolutionBackward0]
	1778094020768 -> 1778094020576
	1778094020768 [label=MulBackward0]
	1778094020960 -> 1778094020768
	1778094020960 [label=MulBackward0]
	1778094021056 -> 1778094020960
	1778094021056 [label=MulBackward0]
	1778094021200 -> 1778094021056
	1778094021200 [label=MulBackward0]
	1778094021296 -> 1778094021200
	1778094021296 [label=ReluBackward0]
	1778094021440 -> 1778094021296
	1778094021440 [label=NativeBatchNormBackward0]
	1778094021536 -> 1778094021440
	1778094021536 [label=ConvolutionBackward0]
	1778094021728 -> 1778094021536
	1778094021728 [label=ReluBackward0]
	1778094021920 -> 1778094021728
	1778094021920 [label=NativeBatchNormBackward0]
	1778094022016 -> 1778094021920
	1778094022016 [label=ConvolutionBackward0]
	1778094022208 -> 1778094022016
	1778094022208 [label=ReluBackward0]
	1778094022400 -> 1778094022208
	1778094022400 [label=NativeBatchNormBackward0]
	1778094022496 -> 1778094022400
	1778094022496 [label=ConvolutionBackward0]
	1778094022688 -> 1778094022496
	1778094022688 [label=MulBackward0]
	1778094022880 -> 1778094022688
	1778094022880 [label=MulBackward0]
	1778094023024 -> 1778094022880
	1778094023024 [label=ReluBackward0]
	1778094023168 -> 1778094023024
	1778094023168 [label=NativeBatchNormBackward0]
	1778094023264 -> 1778094023168
	1778094023264 [label=ConvolutionBackward0]
	1778094023456 -> 1778094023264
	1778094023456 [label=ReluBackward0]
	1778094023648 -> 1778094023456
	1778094023648 [label=NativeBatchNormBackward0]
	1778094023744 -> 1778094023648
	1778094023744 [label=ConvolutionBackward0]
	1778094023936 -> 1778094023744
	1778094023936 [label=ReluBackward0]
	1778094024128 -> 1778094023936
	1778094024128 [label=NativeBatchNormBackward0]
	1778094024224 -> 1778094024128
	1778094024224 [label=ConvolutionBackward0]
	1778094024416 -> 1778094024224
	1778094024416 [label=CatBackward0]
	1778094024608 -> 1778094024416
	1778094024608 [label=UpsampleBilinear2DBackward0]
	1778094024752 -> 1778094024608
	1778094024752 [label=UpsampleBilinear2DBackward0]
	1778094024848 -> 1778094024752
	1778094024848 [label=MulBackward0]
	1778094024944 -> 1778094024848
	1778094024944 [label=MulBackward0]
	1778094025088 -> 1778094024944
	1778094025088 [label=ReluBackward0]
	1778094025232 -> 1778094025088
	1778094025232 [label=NativeBatchNormBackward0]
	1778094025328 -> 1778094025232
	1778094025328 [label=ConvolutionBackward0]
	1778094025520 -> 1778094025328
	1778094025520 [label=ReluBackward0]
	1778094025712 -> 1778094025520
	1778094025712 [label=NativeBatchNormBackward0]
	1778094025808 -> 1778094025712
	1778094025808 [label=ConvolutionBackward0]
	1778094026000 -> 1778094025808
	1778094026000 [label=ReluBackward0]
	1778094026192 -> 1778094026000
	1778094026192 [label=NativeBatchNormBackward0]
	1778094026288 -> 1778094026192
	1778094026288 [label=ConvolutionBackward0]
	1778094026480 -> 1778094026288
	1778094026480 [label=CatBackward0]
	1778094026672 -> 1778094026480
	1778094026672 [label=UpsampleBilinear2DBackward0]
	1778094026816 -> 1778094026672
	1778094026816 [label=UpsampleBilinear2DBackward0]
	1778094026912 -> 1778094026816
	1778094026912 [label=MulBackward0]
	1778094027008 -> 1778094026912
	1778094027008 [label=MulBackward0]
	1778094027152 -> 1778094027008
	1778094027152 [label=ReluBackward0]
	1778094027296 -> 1778094027152
	1778094027296 [label=NativeBatchNormBackward0]
	1778094027392 -> 1778094027296
	1778094027392 [label=ConvolutionBackward0]
	1778094027584 -> 1778094027392
	1778094027584 [label=ReluBackward0]
	1778094027776 -> 1778094027584
	1778094027776 [label=NativeBatchNormBackward0]
	1778094027872 -> 1778094027776
	1778094027872 [label=ConvolutionBackward0]
	1778094028064 -> 1778094027872
	1778094028064 [label=ReluBackward0]
	1778094028256 -> 1778094028064
	1778094028256 [label=NativeBatchNormBackward0]
	1778094028352 -> 1778094028256
	1778094028352 [label=ConvolutionBackward0]
	1778094028544 -> 1778094028352
	1778094028544 [label=CatBackward0]
	1778094028736 -> 1778094028544
	1778094028736 [label=UpsampleBilinear2DBackward0]
	1778094028880 -> 1778094028736
	1778094028880 [label=UpsampleBilinear2DBackward0]
	1778094028976 -> 1778094028880
	1778094028976 [label=MulBackward0]
	1778094029072 -> 1778094028976
	1778094029072 [label=MulBackward0]
	1778094029216 -> 1778094029072
	1778094029216 [label=ReluBackward0]
	1778094029360 -> 1778094029216
	1778094029360 [label=NativeBatchNormBackward0]
	1778094029456 -> 1778094029360
	1778094029456 [label=ConvolutionBackward0]
	1778094029648 -> 1778094029456
	1778094029648 [label=ReluBackward0]
	1778094029840 -> 1778094029648
	1778094029840 [label=NativeBatchNormBackward0]
	1778094029936 -> 1778094029840
	1778094029936 [label=ConvolutionBackward0]
	1778094030128 -> 1778094029936
	1778094030128 [label=ReluBackward0]
	1778094030320 -> 1778094030128
	1778094030320 [label=NativeBatchNormBackward0]
	1778094030368 -> 1778094030320
	1778094030368 [label=ConvolutionBackward0]
	1778094030656 -> 1778094030368
	1778094030656 [label=CatBackward0]
	1778094030800 -> 1778094030656
	1778094030800 [label=UpsampleBilinear2DBackward0]
	1778094276816 -> 1778094030800
	1778094276816 [label=MulBackward0]
	1778094276864 -> 1778094276816
	1778094276864 [label=MulBackward0]
	1778094277104 -> 1778094276864
	1778094277104 [label=ReluBackward0]
	1778094277248 -> 1778094277104
	1778094277248 [label=NativeBatchNormBackward0]
	1778094277296 -> 1778094277248
	1778094277296 [label=ConvolutionBackward0]
	1778094277584 -> 1778094277296
	1778094277584 [label=ReluBackward0]
	1778094277776 -> 1778094277584
	1778094277776 [label=NativeBatchNormBackward0]
	1778094277824 -> 1778094277776
	1778094277824 [label=ConvolutionBackward0]
	1778094278112 -> 1778094277824
	1778094278112 [label=ReluBackward0]
	1778094278304 -> 1778094278112
	1778094278304 [label=NativeBatchNormBackward0]
	1778094278352 -> 1778094278304
	1778094278352 [label=ConvolutionBackward0]
	1778094278640 -> 1778094278352
	1778094278640 [label=CatBackward0]
	1778094278832 -> 1778094278640
	1778094278832 [label=UpsampleBilinear2DBackward0]
	1778094278976 -> 1778094278832
	1778094278976 [label=UpsampleBilinear2DBackward0]
	1778094279024 -> 1778094278976
	1778094279024 [label=MulBackward0]
	1778094279168 -> 1778094279024
	1778094279168 [label=MulBackward0]
	1778094279408 -> 1778094279168
	1778094279408 [label=ReluBackward0]
	1778094279552 -> 1778094279408
	1778094279552 [label=NativeBatchNormBackward0]
	1778094279600 -> 1778094279552
	1778094279600 [label=ConvolutionBackward0]
	1778094279888 -> 1778094279600
	1778094279888 [label=ReluBackward0]
	1778094280080 -> 1778094279888
	1778094280080 [label=NativeBatchNormBackward0]
	1778094280128 -> 1778094280080
	1778094280128 [label=ConvolutionBackward0]
	1778094280416 -> 1778094280128
	1778094280416 [label=ReluBackward0]
	1778094280608 -> 1778094280416
	1778094280608 [label=NativeBatchNormBackward0]
	1778094280656 -> 1778094280608
	1778094280656 [label=ConvolutionBackward0]
	1778094280944 -> 1778094280656
	1778094280944 [label=ReluBackward0]
	1778094281136 -> 1778094280944
	1778094281136 [label=NativeBatchNormBackward0]
	1778094281184 -> 1778094281136
	1778094281184 [label=ConvolutionBackward0]
	1778094278784 -> 1778094281184
	1778094278784 [label=MulBackward0]
	1778094281616 -> 1778094278784
	1778094281616 [label=MulBackward0]
	1778094281712 -> 1778094281616
	1778094281712 [label=ReluBackward0]
	1778094281904 -> 1778094281712
	1778094281904 [label=NativeBatchNormBackward0]
	1778094281952 -> 1778094281904
	1778094281952 [label=ConvolutionBackward0]
	1778094282240 -> 1778094281952
	1778094282240 [label=ReluBackward0]
	1778094282432 -> 1778094282240
	1778094282432 [label=NativeBatchNormBackward0]
	1778094282480 -> 1778094282432
	1778094282480 [label=ConvolutionBackward0]
	1778094282768 -> 1778094282480
	1778094282768 [label=ReluBackward0]
	1778094282960 -> 1778094282768
	1778094282960 [label=NativeBatchNormBackward0]
	1778094283008 -> 1778094282960
	1778094283008 [label=ConvolutionBackward0]
	1778094283296 -> 1778094283008
	1778094283296 [label=MaxPool2DWithIndicesBackward0]
	1778094030752 -> 1778094283296
	1778094030752 [label=MulBackward0]
	1778094283392 -> 1778094030752
	1778094283392 [label=MulBackward0]
	1778094283728 -> 1778094283392
	1778094283728 [label=ReluBackward0]
	1778094283872 -> 1778094283728
	1778094283872 [label=NativeBatchNormBackward0]
	1778094283920 -> 1778094283872
	1778094283920 [label=ConvolutionBackward0]
	1778094284208 -> 1778094283920
	1778094284208 [label=ReluBackward0]
	1778094284400 -> 1778094284208
	1778094284400 [label=NativeBatchNormBackward0]
	1778094284448 -> 1778094284400
	1778094284448 [label=ConvolutionBackward0]
	1778094284736 -> 1778094284448
	1778094284736 [label=ReluBackward0]
	1778094284928 -> 1778094284736
	1778094284928 [label=NativeBatchNormBackward0]
	1778094284976 -> 1778094284928
	1778094284976 [label=ConvolutionBackward0]
	1778094285264 -> 1778094284976
	1778094285264 [label=MaxPool2DWithIndicesBackward0]
	1778094028688 -> 1778094285264
	1778094028688 [label=MulBackward0]
	1778094285360 -> 1778094028688
	1778094285360 [label=MulBackward0]
	1778094285696 -> 1778094285360
	1778094285696 [label=ReluBackward0]
	1778094285840 -> 1778094285696
	1778094285840 [label=NativeBatchNormBackward0]
	1778094285888 -> 1778094285840
	1778094285888 [label=ConvolutionBackward0]
	1778094286176 -> 1778094285888
	1778094286176 [label=ReluBackward0]
	1778094286368 -> 1778094286176
	1778094286368 [label=NativeBatchNormBackward0]
	1778094286416 -> 1778094286368
	1778094286416 [label=ConvolutionBackward0]
	1778094286704 -> 1778094286416
	1778094286704 [label=ReluBackward0]
	1778094286896 -> 1778094286704
	1778094286896 [label=NativeBatchNormBackward0]
	1778094286944 -> 1778094286896
	1778094286944 [label=ConvolutionBackward0]
	1778094287232 -> 1778094286944
	1778094287232 [label=MaxPool2DWithIndicesBackward0]
	1778094026624 -> 1778094287232
	1778094026624 [label=MulBackward0]
	1778094287328 -> 1778094026624
	1778094287328 [label=MulBackward0]
	1778094287664 -> 1778094287328
	1778094287664 [label=ReluBackward0]
	1778094287808 -> 1778094287664
	1778094287808 [label=NativeBatchNormBackward0]
	1778094287856 -> 1778094287808
	1778094287856 [label=ConvolutionBackward0]
	1778094288144 -> 1778094287856
	1778094288144 [label=ReluBackward0]
	1778094288336 -> 1778094288144
	1778094288336 [label=NativeBatchNormBackward0]
	1778094288384 -> 1778094288336
	1778094288384 [label=ConvolutionBackward0]
	1778094288672 -> 1778094288384
	1778094288672 [label=ReluBackward0]
	1778094288864 -> 1778094288672
	1778094288864 [label=NativeBatchNormBackward0]
	1778094288912 -> 1778094288864
	1778094288912 [label=ConvolutionBackward0]
	1778094289200 -> 1778094288912
	1778094289200 [label=MaxPool2DWithIndicesBackward0]
	1778094024560 -> 1778094289200
	1778094024560 [label=MulBackward0]
	1778094289296 -> 1778094024560
	1778094289296 [label=MulBackward0]
	1778094289632 -> 1778094289296
	1778094289632 [label=ReluBackward0]
	1778094289776 -> 1778094289632
	1778094289776 [label=NativeBatchNormBackward0]
	1778094289824 -> 1778094289776
	1778094289824 [label=ConvolutionBackward0]
	1778094290112 -> 1778094289824
	1778094290112 [label=ReluBackward0]
	1778094290304 -> 1778094290112
	1778094290304 [label=NativeBatchNormBackward0]
	1778094290352 -> 1778094290304
	1778094290352 [label=ConvolutionBackward0]
	1778094290640 -> 1778094290352
	1778094290640 [label=ReluBackward0]
	1778094290832 -> 1778094290640
	1778094290832 [label=NativeBatchNormBackward0]
	1778094290880 -> 1778094290832
	1778094290880 [label=ConvolutionBackward0]
	1778094291168 -> 1778094290880
	1777380452112 [label="encoder_blocks.0.0.weight
 (32, 1, 3, 3)" fillcolor=lightblue]
	1777380452112 -> 1778094291168
	1778094291168 [label=AccumulateGrad]
	1778094291120 -> 1778094290880
	1777380442752 [label="encoder_blocks.0.0.bias
 (32)" fillcolor=lightblue]
	1777380442752 -> 1778094291120
	1778094291120 [label=AccumulateGrad]
	1778094290736 -> 1778094290832
	1777380451392 [label="encoder_blocks.0.1.weight
 (32)" fillcolor=lightblue]
	1777380451392 -> 1778094290736
	1778094290736 [label=AccumulateGrad]
	1778094290976 -> 1778094290832
	1777380451312 [label="encoder_blocks.0.1.bias
 (32)" fillcolor=lightblue]
	1777380451312 -> 1778094290976
	1778094290976 [label=AccumulateGrad]
	1778094290592 -> 1778094290352
	1777380450832 [label="encoder_blocks.0.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1777380450832 -> 1778094290592
	1778094290592 [label=AccumulateGrad]
	1778094290544 -> 1778094290352
	1777380450752 [label="encoder_blocks.0.3.bias
 (32)" fillcolor=lightblue]
	1777380450752 -> 1778094290544
	1778094290544 [label=AccumulateGrad]
	1778094290208 -> 1778094290304
	1777380457392 [label="encoder_blocks.0.4.weight
 (32)" fillcolor=lightblue]
	1777380457392 -> 1778094290208
	1778094290208 [label=AccumulateGrad]
	1778094290448 -> 1778094290304
	1777380457312 [label="encoder_blocks.0.4.bias
 (32)" fillcolor=lightblue]
	1777380457312 -> 1778094290448
	1778094290448 [label=AccumulateGrad]
	1778094290064 -> 1778094289824
	1777380450432 [label="encoder_blocks.0.6.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1777380450432 -> 1778094290064
	1778094290064 [label=AccumulateGrad]
	1778094290016 -> 1778094289824
	1777380457072 [label="encoder_blocks.0.6.bias
 (32)" fillcolor=lightblue]
	1777380457072 -> 1778094290016
	1778094290016 [label=AccumulateGrad]
	1778094289680 -> 1778094289776
	1777380456992 [label="encoder_blocks.0.7.weight
 (32)" fillcolor=lightblue]
	1777380456992 -> 1778094289680
	1778094289680 [label=AccumulateGrad]
	1778094289920 -> 1778094289776
	1777380450352 [label="encoder_blocks.0.7.bias
 (32)" fillcolor=lightblue]
	1777380450352 -> 1778094289920
	1778094289920 [label=AccumulateGrad]
	1778094289584 -> 1778094289296
	1778094289584 [label=SigmoidBackward0]
	1778094290496 -> 1778094289584
	1778094290496 [label=AddBackward0]
	1778084271472 -> 1778094290496
	1778084271472 [label=ConvolutionBackward0]
	1778094290784 -> 1778084271472
	1778094290784 [label=ReluBackward0]
	1778094291312 -> 1778094290784
	1778094291312 [label=ConvolutionBackward0]
	1778094291216 -> 1778094291312
	1778094291216 [label=MeanBackward1]
	1778094289632 -> 1778094291216
	1778094291072 -> 1778094291312
	1777380449712 [label="encoder_attentions.0.0.mlp.0.weight
 (2, 32, 1, 1)" fillcolor=lightblue]
	1777380449712 -> 1778094291072
	1778094291072 [label=AccumulateGrad]
	1778094291024 -> 1778084271472
	1777380456272 [label="encoder_attentions.0.0.mlp.2.weight
 (32, 2, 1, 1)" fillcolor=lightblue]
	1777380456272 -> 1778094291024
	1778094291024 [label=AccumulateGrad]
	1778094290160 -> 1778094290496
	1778094290160 [label=ConvolutionBackward0]
	1778094291264 -> 1778094290160
	1778094291264 [label=ReluBackward0]
	1778094291456 -> 1778094291264
	1778094291456 [label=ConvolutionBackward0]
	1778094291504 -> 1778094291456
	1778094291504 [label=AdaptiveMaxPool2DBackward0]
	1778094289632 -> 1778094291504
	1778094291072 -> 1778094291456
	1778094291024 -> 1778094290160
	1778094289344 -> 1778094024560
	1778094289344 [label=SigmoidBackward0]
	1778093209488 -> 1778094289344
	1778093209488 [label=ConvolutionBackward0]
	1778094291360 -> 1778093209488
	1778094291360 [label=CatBackward0]
	1778094291552 -> 1778094291360
	1778094291552 [label=MeanBackward1]
	1778094289296 -> 1778094291552
	1778094291408 -> 1778094291360
	1778094291408 [label=MaxBackward0]
	1778094289296 -> 1778094291408
	1778094290256 -> 1778093209488
	1777380449792 [label="encoder_attentions.0.1.conv.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	1777380449792 -> 1778094290256
	1778094290256 [label=AccumulateGrad]
	1778094289152 -> 1778094288912
	1777380456352 [label="encoder_blocks.1.0.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	1777380456352 -> 1778094289152
	1778094289152 [label=AccumulateGrad]
	1778094289104 -> 1778094288912
	1777380449552 [label="encoder_blocks.1.0.bias
 (64)" fillcolor=lightblue]
	1777380449552 -> 1778094289104
	1778094289104 [label=AccumulateGrad]
	1778094288768 -> 1778094288864
	1777380449472 [label="encoder_blocks.1.1.weight
 (64)" fillcolor=lightblue]
	1777380449472 -> 1778094288768
	1778094288768 [label=AccumulateGrad]
	1778094289008 -> 1778094288864
	1777380456112 [label="encoder_blocks.1.1.bias
 (64)" fillcolor=lightblue]
	1777380456112 -> 1778094289008
	1778094289008 [label=AccumulateGrad]
	1778094288624 -> 1778094288384
	1777380449232 [label="encoder_blocks.1.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1777380449232 -> 1778094288624
	1778094288624 [label=AccumulateGrad]
	1778094288576 -> 1778094288384
	1777380449152 [label="encoder_blocks.1.3.bias
 (64)" fillcolor=lightblue]
	1777380449152 -> 1778094288576
	1778094288576 [label=AccumulateGrad]
	1778094288240 -> 1778094288336
	1777380455792 [label="encoder_blocks.1.4.weight
 (64)" fillcolor=lightblue]
	1777380455792 -> 1778094288240
	1778094288240 [label=AccumulateGrad]
	1778094288480 -> 1778094288336
	1777380455712 [label="encoder_blocks.1.4.bias
 (64)" fillcolor=lightblue]
	1777380455712 -> 1778094288480
	1778094288480 [label=AccumulateGrad]
	1778094288096 -> 1778094287856
	1777380448672 [label="encoder_blocks.1.6.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1777380448672 -> 1778094288096
	1778094288096 [label=AccumulateGrad]
	1778094288048 -> 1778094287856
	1777380455312 [label="encoder_blocks.1.6.bias
 (64)" fillcolor=lightblue]
	1777380455312 -> 1778094288048
	1778094288048 [label=AccumulateGrad]
	1778094287712 -> 1778094287808
	1777380455232 [label="encoder_blocks.1.7.weight
 (64)" fillcolor=lightblue]
	1777380455232 -> 1778094287712
	1778094287712 [label=AccumulateGrad]
	1778094287952 -> 1778094287808
	1777380448592 [label="encoder_blocks.1.7.bias
 (64)" fillcolor=lightblue]
	1777380448592 -> 1778094287952
	1778094287952 [label=AccumulateGrad]
	1778094287616 -> 1778094287328
	1778094287616 [label=SigmoidBackward0]
	1778091977568 -> 1778094287616
	1778091977568 [label=AddBackward0]
	1778094288288 -> 1778091977568
	1778094288288 [label=ConvolutionBackward0]
	1778094288816 -> 1778094288288
	1778094288816 [label=ReluBackward0]
	1778094289392 -> 1778094288816
	1778094289392 [label=ConvolutionBackward0]
	1778094289968 -> 1778094289392
	1778094289968 [label=MeanBackward1]
	1778094287664 -> 1778094289968
	1778094289488 -> 1778094289392
	1777380454992 [label="encoder_attentions.1.0.mlp.0.weight
 (4, 64, 1, 1)" fillcolor=lightblue]
	1777380454992 -> 1778094289488
	1778094289488 [label=AccumulateGrad]
	1778094288720 -> 1778094288288
	1777380448272 [label="encoder_attentions.1.0.mlp.2.weight
 (64, 4, 1, 1)" fillcolor=lightblue]
	1777380448272 -> 1778094288720
	1778094288720 [label=AccumulateGrad]
	1778094288192 -> 1778091977568
	1778094288192 [label=ConvolutionBackward0]
	1778094289248 -> 1778094288192
	1778094289248 [label=ReluBackward0]
	1778094289728 -> 1778094289248
	1778094289728 [label=ConvolutionBackward0]
	1778094290688 -> 1778094289728
	1778094290688 [label=AdaptiveMaxPool2DBackward0]
	1778094287664 -> 1778094290688
	1778094289488 -> 1778094289728
	1778094288720 -> 1778094288192
	1778094287376 -> 1778094026624
	1778094287376 [label=SigmoidBackward0]
	1778094287760 -> 1778094287376
	1778094287760 [label=ConvolutionBackward0]
	1778094289056 -> 1778094287760
	1778094289056 [label=CatBackward0]
	1778094291648 -> 1778094289056
	1778094291648 [label=MeanBackward1]
	1778094287328 -> 1778094291648
	1778094291696 -> 1778094289056
	1778094291696 [label=MaxBackward0]
	1778094287328 -> 1778094291696
	1778094289536 -> 1778094287760
	1777380454832 [label="encoder_attentions.1.1.conv.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	1777380454832 -> 1778094289536
	1778094289536 [label=AccumulateGrad]
	1778094287184 -> 1778094286944
	1777380454752 [label="encoder_blocks.2.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	1777380454752 -> 1778094287184
	1778094287184 [label=AccumulateGrad]
	1778094287136 -> 1778094286944
	1777380448112 [label="encoder_blocks.2.0.bias
 (128)" fillcolor=lightblue]
	1777380448112 -> 1778094287136
	1778094287136 [label=AccumulateGrad]
	1778094286800 -> 1778094286896
	1777380448032 [label="encoder_blocks.2.1.weight
 (128)" fillcolor=lightblue]
	1777380448032 -> 1778094286800
	1778094286800 [label=AccumulateGrad]
	1778094287040 -> 1778094286896
	1777380454672 [label="encoder_blocks.2.1.bias
 (128)" fillcolor=lightblue]
	1777380454672 -> 1778094287040
	1778094287040 [label=AccumulateGrad]
	1778094286656 -> 1778094286416
	1777380448912 [label="encoder_blocks.2.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1777380448912 -> 1778094286656
	1778094286656 [label=AccumulateGrad]
	1778094286608 -> 1778094286416
	1777380448832 [label="encoder_blocks.2.3.bias
 (128)" fillcolor=lightblue]
	1777380448832 -> 1778094286608
	1778094286608 [label=AccumulateGrad]
	1778094286272 -> 1778094286368
	1777380455472 [label="encoder_blocks.2.4.weight
 (128)" fillcolor=lightblue]
	1777380455472 -> 1778094286272
	1778094286272 [label=AccumulateGrad]
	1778094286512 -> 1778094286368
	1777380455392 [label="encoder_blocks.2.4.bias
 (128)" fillcolor=lightblue]
	1777380455392 -> 1778094286512
	1778094286512 [label=AccumulateGrad]
	1778094286128 -> 1778094285888
	1777380459536 [label="encoder_blocks.2.6.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1777380459536 -> 1778094286128
	1778094286128 [label=AccumulateGrad]
	1778094286080 -> 1778094285888
	1777380459456 [label="encoder_blocks.2.6.bias
 (128)" fillcolor=lightblue]
	1777380459456 -> 1778094286080
	1778094286080 [label=AccumulateGrad]
	1778094285744 -> 1778094285840
	1777380466256 [label="encoder_blocks.2.7.weight
 (128)" fillcolor=lightblue]
	1777380466256 -> 1778094285744
	1778094285744 [label=AccumulateGrad]
	1778094285984 -> 1778094285840
	1777380466176 [label="encoder_blocks.2.7.bias
 (128)" fillcolor=lightblue]
	1777380466176 -> 1778094285984
	1778094285984 [label=AccumulateGrad]
	1778094285648 -> 1778094285360
	1778094285648 [label=SigmoidBackward0]
	1778094286560 -> 1778094285648
	1778094286560 [label=AddBackward0]
	1778094286224 -> 1778094286560
	1778094286224 [label=ConvolutionBackward0]
	1778094286752 -> 1778094286224
	1778094286752 [label=ReluBackward0]
	1778094287280 -> 1778094286752
	1778094287280 [label=ConvolutionBackward0]
	1778094287568 -> 1778094287280
	1778094287568 [label=MeanBackward1]
	1778094285696 -> 1778094287568
	1778094288000 -> 1778094287280
	1777380459136 [label="encoder_attentions.2.0.mlp.0.weight
 (8, 128, 1, 1)" fillcolor=lightblue]
	1777380459136 -> 1778094288000
	1778094288000 [label=AccumulateGrad]
	1778094286848 -> 1778094286224
	1777380465856 [label="encoder_attentions.2.0.mlp.2.weight
 (128, 8, 1, 1)" fillcolor=lightblue]
	1777380465856 -> 1778094286848
	1778094286848 [label=AccumulateGrad]
	1778094286320 -> 1778094286560
	1778094286320 [label=ConvolutionBackward0]
	1778094287424 -> 1778094286320
	1778094287424 [label=ReluBackward0]
	1778094291600 -> 1778094287424
	1778094291600 [label=ConvolutionBackward0]
	1778094291792 -> 1778094291600
	1778094291792 [label=AdaptiveMaxPool2DBackward0]
	1778094285696 -> 1778094291792
	1778094288000 -> 1778094291600
	1778094286848 -> 1778094286320
	1778094285408 -> 1778094028688
	1778094285408 [label=SigmoidBackward0]
	1778094285792 -> 1778094285408
	1778094285792 [label=ConvolutionBackward0]
	1778094287520 -> 1778094285792
	1778094287520 [label=CatBackward0]
	1778094291840 -> 1778094287520
	1778094291840 [label=MeanBackward1]
	1778094285360 -> 1778094291840
	1778094291888 -> 1778094287520
	1778094291888 [label=MaxBackward0]
	1778094285360 -> 1778094291888
	1778094291744 -> 1778094285792
	1777380458976 [label="encoder_attentions.2.1.conv.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	1777380458976 -> 1778094291744
	1778094291744 [label=AccumulateGrad]
	1778094285216 -> 1778094284976
	1777380465696 [label="encoder_blocks.3.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	1777380465696 -> 1778094285216
	1778094285216 [label=AccumulateGrad]
	1778094285168 -> 1778094284976
	1777380458816 [label="encoder_blocks.3.0.bias
 (256)" fillcolor=lightblue]
	1777380458816 -> 1778094285168
	1778094285168 [label=AccumulateGrad]
	1778094284832 -> 1778094284928
	1777380458896 [label="encoder_blocks.3.1.weight
 (256)" fillcolor=lightblue]
	1777380458896 -> 1778094284832
	1778094284832 [label=AccumulateGrad]
	1778094285072 -> 1778094284928
	1777380465616 [label="encoder_blocks.3.1.bias
 (256)" fillcolor=lightblue]
	1777380465616 -> 1778094285072
	1778094285072 [label=AccumulateGrad]
	1778094284688 -> 1778094284448
	1777380465216 [label="encoder_blocks.3.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1777380465216 -> 1778094284688
	1778094284688 [label=AccumulateGrad]
	1778094284640 -> 1778094284448
	1777380458576 [label="encoder_blocks.3.3.bias
 (256)" fillcolor=lightblue]
	1777380458576 -> 1778094284640
	1778094284640 [label=AccumulateGrad]
	1778094284304 -> 1778094284400
	1777380464976 [label="encoder_blocks.3.4.weight
 (256)" fillcolor=lightblue]
	1777380464976 -> 1778094284304
	1778094284304 [label=AccumulateGrad]
	1778094284544 -> 1778094284400
	1777380464896 [label="encoder_blocks.3.4.bias
 (256)" fillcolor=lightblue]
	1777380464896 -> 1778094284544
	1778094284544 [label=AccumulateGrad]
	1778094284160 -> 1778094283920
	1777380464736 [label="encoder_blocks.3.6.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1777380464736 -> 1778094284160
	1778094284160 [label=AccumulateGrad]
	1778094284112 -> 1778094283920
	1777380464656 [label="encoder_blocks.3.6.bias
 (256)" fillcolor=lightblue]
	1777380464656 -> 1778094284112
	1778094284112 [label=AccumulateGrad]
	1778094283776 -> 1778094283872
	1777380464576 [label="encoder_blocks.3.7.weight
 (256)" fillcolor=lightblue]
	1777380464576 -> 1778094283776
	1778094283776 [label=AccumulateGrad]
	1778094284016 -> 1778094283872
	1777380464496 [label="encoder_blocks.3.7.bias
 (256)" fillcolor=lightblue]
	1777380464496 -> 1778094284016
	1778094284016 [label=AccumulateGrad]
	1778094283680 -> 1778094283392
	1778094283680 [label=SigmoidBackward0]
	1778094284592 -> 1778094283680
	1778094284592 [label=AddBackward0]
	1778094284256 -> 1778094284592
	1778094284256 [label=ConvolutionBackward0]
	1778094284784 -> 1778094284256
	1778094284784 [label=ReluBackward0]
	1778094285312 -> 1778094284784
	1778094285312 [label=ConvolutionBackward0]
	1778094285600 -> 1778094285312
	1778094285600 [label=MeanBackward1]
	1778094283728 -> 1778094285600
	1778094286032 -> 1778094285312
	1777380464016 [label="encoder_attentions.3.0.mlp.0.weight
 (16, 256, 1, 1)" fillcolor=lightblue]
	1777380464016 -> 1778094286032
	1778094286032 [label=AccumulateGrad]
	1778094284880 -> 1778094284256
	1777380463856 [label="encoder_attentions.3.0.mlp.2.weight
 (256, 16, 1, 1)" fillcolor=lightblue]
	1777380463856 -> 1778094284880
	1778094284880 [label=AccumulateGrad]
	1778094284352 -> 1778094284592
	1778094284352 [label=ConvolutionBackward0]
	1778094288528 -> 1778094284352
	1778094288528 [label=ReluBackward0]
	1778094291936 -> 1778094288528
	1778094291936 [label=ConvolutionBackward0]
	1778094291984 -> 1778094291936
	1778094291984 [label=AdaptiveMaxPool2DBackward0]
	1778094283728 -> 1778094291984
	1778094286032 -> 1778094291936
	1778094284880 -> 1778094284352
	1778094283440 -> 1778094030752
	1778094283440 [label=SigmoidBackward0]
	1778094283824 -> 1778094283440
	1778094283824 [label=ConvolutionBackward0]
	1778094285552 -> 1778094283824
	1778094285552 [label=CatBackward0]
	1778094292032 -> 1778094285552
	1778094292032 [label=MeanBackward1]
	1778094283392 -> 1778094292032
	1778094292080 -> 1778094285552
	1778094292080 [label=MaxBackward0]
	1778094283392 -> 1778094292080
	1778094285456 -> 1778094283824
	1777380463696 [label="encoder_attentions.3.1.conv.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	1777380463696 -> 1778094285456
	1778094285456 [label=AccumulateGrad]
	1778094283248 -> 1778094283008
	1777380463536 [label="encoder_blocks.4.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1777380463536 -> 1778094283248
	1778094283248 [label=AccumulateGrad]
	1778094283200 -> 1778094283008
	1777380463456 [label="encoder_blocks.4.0.bias
 (256)" fillcolor=lightblue]
	1777380463456 -> 1778094283200
	1778094283200 [label=AccumulateGrad]
	1778094282864 -> 1778094282960
	1777380463376 [label="encoder_blocks.4.1.weight
 (256)" fillcolor=lightblue]
	1777380463376 -> 1778094282864
	1778094282864 [label=AccumulateGrad]
	1778094283104 -> 1778094282960
	1777380463296 [label="encoder_blocks.4.1.bias
 (256)" fillcolor=lightblue]
	1777380463296 -> 1778094283104
	1778094283104 [label=AccumulateGrad]
	1778094282720 -> 1778094282480
	1777380462656 [label="encoder_blocks.4.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1777380462656 -> 1778094282720
	1778094282720 [label=AccumulateGrad]
	1778094282672 -> 1778094282480
	1777380462896 [label="encoder_blocks.4.3.bias
 (256)" fillcolor=lightblue]
	1777380462896 -> 1778094282672
	1778094282672 [label=AccumulateGrad]
	1778094282336 -> 1778094282432
	1777380462816 [label="encoder_blocks.4.4.weight
 (256)" fillcolor=lightblue]
	1777380462816 -> 1778094282336
	1778094282336 [label=AccumulateGrad]
	1778094282576 -> 1778094282432
	1777380462576 [label="encoder_blocks.4.4.bias
 (256)" fillcolor=lightblue]
	1777380462576 -> 1778094282576
	1778094282576 [label=AccumulateGrad]
	1778094282192 -> 1778094281952
	1777380462096 [label="encoder_blocks.4.6.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1777380462096 -> 1778094282192
	1778094282192 [label=AccumulateGrad]
	1778094282144 -> 1778094281952
	1777380462016 [label="encoder_blocks.4.6.bias
 (256)" fillcolor=lightblue]
	1777380462016 -> 1778094282144
	1778094282144 [label=AccumulateGrad]
	1778094281808 -> 1778094281904
	1777380461776 [label="encoder_blocks.4.7.weight
 (256)" fillcolor=lightblue]
	1777380461776 -> 1778094281808
	1778094281808 [label=AccumulateGrad]
	1778094282048 -> 1778094281904
	1777380461696 [label="encoder_blocks.4.7.bias
 (256)" fillcolor=lightblue]
	1777380461696 -> 1778094282048
	1778094282048 [label=AccumulateGrad]
	1778094281760 -> 1778094281616
	1778094281760 [label=SigmoidBackward0]
	1778094282624 -> 1778094281760
	1778094282624 [label=AddBackward0]
	1778094282288 -> 1778094282624
	1778094282288 [label=ConvolutionBackward0]
	1778094282816 -> 1778094282288
	1778094282816 [label=ReluBackward0]
	1778094283344 -> 1778094282816
	1778094283344 [label=ConvolutionBackward0]
	1778094283632 -> 1778094283344
	1778094283632 [label=MeanBackward1]
	1778094281712 -> 1778094283632
	1778094284064 -> 1778094283344
	1777380461216 [label="encoder_attentions.4.0.mlp.0.weight
 (16, 256, 1, 1)" fillcolor=lightblue]
	1777380461216 -> 1778094284064
	1778094284064 [label=AccumulateGrad]
	1778094282912 -> 1778094282288
	1777380461056 [label="encoder_attentions.4.0.mlp.2.weight
 (256, 16, 1, 1)" fillcolor=lightblue]
	1777380461056 -> 1778094282912
	1778094282912 [label=AccumulateGrad]
	1778094282384 -> 1778094282624
	1778094282384 [label=ConvolutionBackward0]
	1778094287088 -> 1778094282384
	1778094287088 [label=ReluBackward0]
	1778094292128 -> 1778094287088
	1778094292128 [label=ConvolutionBackward0]
	1778094292176 -> 1778094292128
	1778094292176 [label=AdaptiveMaxPool2DBackward0]
	1778094281712 -> 1778094292176
	1778094284064 -> 1778094292128
	1778094282912 -> 1778094282384
	1778094281568 -> 1778094278784
	1778094281568 [label=SigmoidBackward0]
	1778094281856 -> 1778094281568
	1778094281856 [label=ConvolutionBackward0]
	1778094283584 -> 1778094281856
	1778094283584 [label=CatBackward0]
	1778094292224 -> 1778094283584
	1778094292224 [label=MeanBackward1]
	1778094281616 -> 1778094292224
	1778094292272 -> 1778094283584
	1778094292272 [label=MaxBackward0]
	1778094281616 -> 1778094292272
	1778094283488 -> 1778094281856
	1777380460896 [label="encoder_attentions.4.1.conv.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	1777380460896 -> 1778094283488
	1778094283488 [label=AccumulateGrad]
	1778094281472 -> 1778094281184
	1777380461856 [label="bottleneck.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1777380461856 -> 1778094281472
	1778094281472 [label=AccumulateGrad]
	1778094281424 -> 1778094281184
	1777380459696 [label="bottleneck.0.bias
 (256)" fillcolor=lightblue]
	1777380459696 -> 1778094281424
	1778094281424 [label=AccumulateGrad]
	1778094281040 -> 1778094281136
	1777380459616 [label="bottleneck.1.weight
 (256)" fillcolor=lightblue]
	1777380459616 -> 1778094281040
	1778094281040 [label=AccumulateGrad]
	1778094281280 -> 1778094281136
	1777380466416 [label="bottleneck.1.bias
 (256)" fillcolor=lightblue]
	1777380466416 -> 1778094281280
	1778094281280 [label=AccumulateGrad]
	1778094280896 -> 1778094280656
	1778093271840 [label="bottleneck.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1778093271840 -> 1778094280896
	1778094280896 [label=AccumulateGrad]
	1778094280848 -> 1778094280656
	1778093271920 [label="bottleneck.3.bias
 (256)" fillcolor=lightblue]
	1778093271920 -> 1778094280848
	1778094280848 [label=AccumulateGrad]
	1778094280512 -> 1778094280608
	1778093272000 [label="bottleneck.4.weight
 (256)" fillcolor=lightblue]
	1778093272000 -> 1778094280512
	1778094280512 [label=AccumulateGrad]
	1778094280752 -> 1778094280608
	1778093272080 [label="bottleneck.4.bias
 (256)" fillcolor=lightblue]
	1778093272080 -> 1778094280752
	1778094280752 [label=AccumulateGrad]
	1778094280368 -> 1778094280128
	1778093272560 [label="bottleneck.6.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1778093272560 -> 1778094280368
	1778094280368 [label=AccumulateGrad]
	1778094280320 -> 1778094280128
	1778093272640 [label="bottleneck.6.bias
 (256)" fillcolor=lightblue]
	1778093272640 -> 1778094280320
	1778094280320 [label=AccumulateGrad]
	1778094279984 -> 1778094280080
	1778093272720 [label="bottleneck.7.weight
 (256)" fillcolor=lightblue]
	1778093272720 -> 1778094279984
	1778094279984 [label=AccumulateGrad]
	1778094280224 -> 1778094280080
	1778093272800 [label="bottleneck.7.bias
 (256)" fillcolor=lightblue]
	1778093272800 -> 1778094280224
	1778094280224 [label=AccumulateGrad]
	1778094279840 -> 1778094279600
	1778093273120 [label="bottleneck.9.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1778093273120 -> 1778094279840
	1778094279840 [label=AccumulateGrad]
	1778094279792 -> 1778094279600
	1778093273280 [label="bottleneck.9.bias
 (256)" fillcolor=lightblue]
	1778093273280 -> 1778094279792
	1778094279792 [label=AccumulateGrad]
	1778094279456 -> 1778094279552
	1778093273360 [label="bottleneck.10.weight
 (256)" fillcolor=lightblue]
	1778093273360 -> 1778094279456
	1778094279456 [label=AccumulateGrad]
	1778094279696 -> 1778094279552
	1778093273440 [label="bottleneck.10.bias
 (256)" fillcolor=lightblue]
	1778093273440 -> 1778094279696
	1778094279696 [label=AccumulateGrad]
	1778094279360 -> 1778094279168
	1778094279360 [label=SigmoidBackward0]
	1778094280272 -> 1778094279360
	1778094280272 [label=AddBackward0]
	1778094279936 -> 1778094280272
	1778094279936 [label=ConvolutionBackward0]
	1778094280464 -> 1778094279936
	1778094280464 [label=ReluBackward0]
	1778094280992 -> 1778094280464
	1778094280992 [label=ConvolutionBackward0]
	1778094281520 -> 1778094280992
	1778094281520 [label=MeanBackward1]
	1778094279408 -> 1778094281520
	1778094282096 -> 1778094280992
	1778093273840 [label="bottleneck_attention.0.mlp.0.weight
 (16, 256, 1, 1)" fillcolor=lightblue]
	1778093273840 -> 1778094282096
	1778094282096 [label=AccumulateGrad]
	1778094280560 -> 1778094279936
	1778093274000 [label="bottleneck_attention.0.mlp.2.weight
 (256, 16, 1, 1)" fillcolor=lightblue]
	1778093274000 -> 1778094280560
	1778094280560 [label=AccumulateGrad]
	1778094280032 -> 1778094280272
	1778094280032 [label=ConvolutionBackward0]
	1778094292320 -> 1778094280032
	1778094292320 [label=ReluBackward0]
	1778094281376 -> 1778094292320
	1778094281376 [label=ConvolutionBackward0]
	1778094283152 -> 1778094281376
	1778094283152 [label=AdaptiveMaxPool2DBackward0]
	1778094279408 -> 1778094283152
	1778094282096 -> 1778094281376
	1778094280560 -> 1778094280032
	1778094279120 -> 1778094279024
	1778094279120 [label=SigmoidBackward0]
	1778094279504 -> 1778094279120
	1778094279504 [label=ConvolutionBackward0]
	1778094281328 -> 1778094279504
	1778094281328 [label=CatBackward0]
	1778094285120 -> 1778094281328
	1778094285120 [label=MeanBackward1]
	1778094279168 -> 1778094285120
	1778094292368 -> 1778094281328
	1778094292368 [label=MaxBackward0]
	1778094279168 -> 1778094292368
	1778094281088 -> 1778094279504
	1778093274160 [label="bottleneck_attention.1.conv.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	1778093274160 -> 1778094281088
	1778094281088 [label=AccumulateGrad]
	1778094278784 -> 1778094278640
	1778094278592 -> 1778094278352
	1778093274320 [label="decoder_blocks.0.0.weight
 (256, 512, 3, 3)" fillcolor=lightblue]
	1778093274320 -> 1778094278592
	1778094278592 [label=AccumulateGrad]
	1778094278544 -> 1778094278352
	1778093274400 [label="decoder_blocks.0.0.bias
 (256)" fillcolor=lightblue]
	1778093274400 -> 1778094278544
	1778094278544 [label=AccumulateGrad]
	1778094278208 -> 1778094278304
	1778093274480 [label="decoder_blocks.0.1.weight
 (256)" fillcolor=lightblue]
	1778093274480 -> 1778094278208
	1778094278208 [label=AccumulateGrad]
	1778094278448 -> 1778094278304
	1778093274560 [label="decoder_blocks.0.1.bias
 (256)" fillcolor=lightblue]
	1778093274560 -> 1778094278448
	1778094278448 [label=AccumulateGrad]
	1778094278064 -> 1778094277824
	1778093275040 [label="decoder_blocks.0.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1778093275040 -> 1778094278064
	1778094278064 [label=AccumulateGrad]
	1778094278016 -> 1778094277824
	1778093275120 [label="decoder_blocks.0.3.bias
 (256)" fillcolor=lightblue]
	1778093275120 -> 1778094278016
	1778094278016 [label=AccumulateGrad]
	1778094277680 -> 1778094277776
	1778093275200 [label="decoder_blocks.0.4.weight
 (256)" fillcolor=lightblue]
	1778093275200 -> 1778094277680
	1778094277680 [label=AccumulateGrad]
	1778094277920 -> 1778094277776
	1778093275280 [label="decoder_blocks.0.4.bias
 (256)" fillcolor=lightblue]
	1778093275280 -> 1778094277920
	1778094277920 [label=AccumulateGrad]
	1778094277536 -> 1778094277296
	1778093275760 [label="decoder_blocks.0.6.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1778093275760 -> 1778094277536
	1778094277536 [label=AccumulateGrad]
	1778094277488 -> 1778094277296
	1778093275840 [label="decoder_blocks.0.6.bias
 (256)" fillcolor=lightblue]
	1778093275840 -> 1778094277488
	1778094277488 [label=AccumulateGrad]
	1778094277152 -> 1778094277248
	1778093275920 [label="decoder_blocks.0.7.weight
 (256)" fillcolor=lightblue]
	1778093275920 -> 1778094277152
	1778094277152 [label=AccumulateGrad]
	1778094277392 -> 1778094277248
	1778093276000 [label="decoder_blocks.0.7.bias
 (256)" fillcolor=lightblue]
	1778093276000 -> 1778094277392
	1778094277392 [label=AccumulateGrad]
	1778094277056 -> 1778094276864
	1778094277056 [label=SigmoidBackward0]
	1778094277968 -> 1778094277056
	1778094277968 [label=AddBackward0]
	1778094277632 -> 1778094277968
	1778094277632 [label=ConvolutionBackward0]
	1778094278160 -> 1778094277632
	1778094278160 [label=ReluBackward0]
	1778094278688 -> 1778094278160
	1778094278688 [label=ConvolutionBackward0]
	1778094279264 -> 1778094278688
	1778094279264 [label=MeanBackward1]
	1778094277104 -> 1778094279264
	1778094278880 -> 1778094278688
	1778093276480 [label="decoder_attentions.0.0.mlp.0.weight
 (16, 256, 1, 1)" fillcolor=lightblue]
	1778093276480 -> 1778094278880
	1778094278880 [label=AccumulateGrad]
	1778094278256 -> 1778094277632
	1778093276640 [label="decoder_attentions.0.0.mlp.2.weight
 (256, 16, 1, 1)" fillcolor=lightblue]
	1778093276640 -> 1778094278256
	1778094278256 [label=AccumulateGrad]
	1778094277728 -> 1778094277968
	1778094277728 [label=ConvolutionBackward0]
	1778094292416 -> 1778094277728
	1778094292416 [label=ReluBackward0]
	1778094279744 -> 1778094292416
	1778094279744 [label=ConvolutionBackward0]
	1778094280800 -> 1778094279744
	1778094280800 [label=AdaptiveMaxPool2DBackward0]
	1778094277104 -> 1778094280800
	1778094278880 -> 1778094279744
	1778094278256 -> 1778094277728
	1778094276720 -> 1778094276816
	1778094276720 [label=SigmoidBackward0]
	1778094277200 -> 1778094276720
	1778094277200 [label=ConvolutionBackward0]
	1778094278928 -> 1778094277200
	1778094278928 [label=CatBackward0]
	1778094281664 -> 1778094278928
	1778094281664 [label=MeanBackward1]
	1778094276864 -> 1778094281664
	1778094292464 -> 1778094278928
	1778094292464 [label=MaxBackward0]
	1778094276864 -> 1778094292464
	1778094278736 -> 1778094277200
	1778093276800 [label="decoder_attentions.0.1.conv.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	1778093276800 -> 1778094278736
	1778094278736 [label=AccumulateGrad]
	1778094030752 -> 1778094030656
	1778094030608 -> 1778094030368
	1778093276960 [label="decoder_blocks.1.0.weight
 (256, 512, 3, 3)" fillcolor=lightblue]
	1778093276960 -> 1778094030608
	1778094030608 [label=AccumulateGrad]
	1778094030560 -> 1778094030368
	1778093277040 [label="decoder_blocks.1.0.bias
 (256)" fillcolor=lightblue]
	1778093277040 -> 1778094030560
	1778094030560 [label=AccumulateGrad]
	1778094030224 -> 1778094030320
	1778093277120 [label="decoder_blocks.1.1.weight
 (256)" fillcolor=lightblue]
	1778093277120 -> 1778094030224
	1778094030224 [label=AccumulateGrad]
	1778094030464 -> 1778094030320
	1778093834320 [label="decoder_blocks.1.1.bias
 (256)" fillcolor=lightblue]
	1778093834320 -> 1778094030464
	1778094030464 [label=AccumulateGrad]
	1778094030080 -> 1778094029936
	1778093834800 [label="decoder_blocks.1.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1778093834800 -> 1778094030080
	1778094030080 [label=AccumulateGrad]
	1778094030032 -> 1778094029936
	1778093834880 [label="decoder_blocks.1.3.bias
 (256)" fillcolor=lightblue]
	1778093834880 -> 1778094030032
	1778094030032 [label=AccumulateGrad]
	1778094029888 -> 1778094029840
	1778093834960 [label="decoder_blocks.1.4.weight
 (256)" fillcolor=lightblue]
	1778093834960 -> 1778094029888
	1778094029888 [label=AccumulateGrad]
	1778094029744 -> 1778094029840
	1778093835040 [label="decoder_blocks.1.4.bias
 (256)" fillcolor=lightblue]
	1778093835040 -> 1778094029744
	1778094029744 [label=AccumulateGrad]
	1778094029600 -> 1778094029456
	1778093835520 [label="decoder_blocks.1.6.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1778093835520 -> 1778094029600
	1778094029600 [label=AccumulateGrad]
	1778094029552 -> 1778094029456
	1778093835600 [label="decoder_blocks.1.6.bias
 (256)" fillcolor=lightblue]
	1778093835600 -> 1778094029552
	1778094029552 [label=AccumulateGrad]
	1778094029408 -> 1778094029360
	1778093835680 [label="decoder_blocks.1.7.weight
 (256)" fillcolor=lightblue]
	1778093835680 -> 1778094029408
	1778094029408 [label=AccumulateGrad]
	1778094029264 -> 1778094029360
	1778093835760 [label="decoder_blocks.1.7.bias
 (256)" fillcolor=lightblue]
	1778093835760 -> 1778094029264
	1778094029264 [label=AccumulateGrad]
	1778094029168 -> 1778094029072
	1778094029168 [label=SigmoidBackward0]
	1778094029984 -> 1778094029168
	1778094029984 [label=AddBackward0]
	1778094029696 -> 1778094029984
	1778094029696 [label=ConvolutionBackward0]
	1778094030176 -> 1778094029696
	1778094030176 [label=ReluBackward0]
	1778094030704 -> 1778094030176
	1778094030704 [label=ConvolutionBackward0]
	1778094277440 -> 1778094030704
	1778094277440 [label=MeanBackward1]
	1778094029216 -> 1778094277440
	1778094276960 -> 1778094030704
	1778093836160 [label="decoder_attentions.1.0.mlp.0.weight
 (16, 256, 1, 1)" fillcolor=lightblue]
	1778093836160 -> 1778094276960
	1778094276960 [label=AccumulateGrad]
	1778094030272 -> 1778094029696
	1778093836320 [label="decoder_attentions.1.0.mlp.2.weight
 (256, 16, 1, 1)" fillcolor=lightblue]
	1778093836320 -> 1778094030272
	1778094030272 [label=AccumulateGrad]
	1778094029792 -> 1778094029984
	1778094029792 [label=ConvolutionBackward0]
	1778094030512 -> 1778094029792
	1778094030512 [label=ReluBackward0]
	1778094277008 -> 1778094030512
	1778094277008 [label=ConvolutionBackward0]
	1778094279312 -> 1778094277008
	1778094279312 [label=AdaptiveMaxPool2DBackward0]
	1778094029216 -> 1778094279312
	1778094276960 -> 1778094277008
	1778094030272 -> 1778094029792
	1778094029024 -> 1778094028976
	1778094029024 [label=SigmoidBackward0]
	1778094029312 -> 1778094029024
	1778094029312 [label=ConvolutionBackward0]
	1778094029120 -> 1778094029312
	1778094029120 [label=CatBackward0]
	1778094292560 -> 1778094029120
	1778094292560 [label=MeanBackward1]
	1778094029072 -> 1778094292560
	1778094292608 -> 1778094029120
	1778094292608 [label=MaxBackward0]
	1778094029072 -> 1778094292608
	1778094276768 -> 1778094029312
	1778093836480 [label="decoder_attentions.1.1.conv.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	1778093836480 -> 1778094276768
	1778094276768 [label=AccumulateGrad]
	1778094028688 -> 1778094028544
	1778094028496 -> 1778094028352
	1778093836640 [label="decoder_blocks.2.0.weight
 (128, 384, 3, 3)" fillcolor=lightblue]
	1778093836640 -> 1778094028496
	1778094028496 [label=AccumulateGrad]
	1778094028448 -> 1778094028352
	1778093836720 [label="decoder_blocks.2.0.bias
 (128)" fillcolor=lightblue]
	1778093836720 -> 1778094028448
	1778094028448 [label=AccumulateGrad]
	1778094028304 -> 1778094028256
	1778093836800 [label="decoder_blocks.2.1.weight
 (128)" fillcolor=lightblue]
	1778093836800 -> 1778094028304
	1778094028304 [label=AccumulateGrad]
	1778094028160 -> 1778094028256
	1778093836880 [label="decoder_blocks.2.1.bias
 (128)" fillcolor=lightblue]
	1778093836880 -> 1778094028160
	1778094028160 [label=AccumulateGrad]
	1778094028016 -> 1778094027872
	1778093837360 [label="decoder_blocks.2.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1778093837360 -> 1778094028016
	1778094028016 [label=AccumulateGrad]
	1778094027968 -> 1778094027872
	1778093837440 [label="decoder_blocks.2.3.bias
 (128)" fillcolor=lightblue]
	1778093837440 -> 1778094027968
	1778094027968 [label=AccumulateGrad]
	1778094027824 -> 1778094027776
	1778093837520 [label="decoder_blocks.2.4.weight
 (128)" fillcolor=lightblue]
	1778093837520 -> 1778094027824
	1778094027824 [label=AccumulateGrad]
	1778094027680 -> 1778094027776
	1778093837600 [label="decoder_blocks.2.4.bias
 (128)" fillcolor=lightblue]
	1778093837600 -> 1778094027680
	1778094027680 [label=AccumulateGrad]
	1778094027536 -> 1778094027392
	1778093838080 [label="decoder_blocks.2.6.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1778093838080 -> 1778094027536
	1778094027536 [label=AccumulateGrad]
	1778094027488 -> 1778094027392
	1778093838160 [label="decoder_blocks.2.6.bias
 (128)" fillcolor=lightblue]
	1778093838160 -> 1778094027488
	1778094027488 [label=AccumulateGrad]
	1778094027344 -> 1778094027296
	1778093838240 [label="decoder_blocks.2.7.weight
 (128)" fillcolor=lightblue]
	1778093838240 -> 1778094027344
	1778094027344 [label=AccumulateGrad]
	1778094027200 -> 1778094027296
	1778093838320 [label="decoder_blocks.2.7.bias
 (128)" fillcolor=lightblue]
	1778093838320 -> 1778094027200
	1778094027200 [label=AccumulateGrad]
	1778094027104 -> 1778094027008
	1778094027104 [label=SigmoidBackward0]
	1778094027920 -> 1778094027104
	1778094027920 [label=AddBackward0]
	1778094027632 -> 1778094027920
	1778094027632 [label=ConvolutionBackward0]
	1778094028112 -> 1778094027632
	1778094028112 [label=ReluBackward0]
	1778094028592 -> 1778094028112
	1778094028592 [label=ConvolutionBackward0]
	1778094028784 -> 1778094028592
	1778094028784 [label=MeanBackward1]
	1778094027152 -> 1778094028784
	1778094028928 -> 1778094028592
	1778093838800 [label="decoder_attentions.2.0.mlp.0.weight
 (8, 128, 1, 1)" fillcolor=lightblue]
	1778093838800 -> 1778094028928
	1778094028928 [label=AccumulateGrad]
	1778094028208 -> 1778094027632
	1778093838960 [label="decoder_attentions.2.0.mlp.2.weight
 (128, 8, 1, 1)" fillcolor=lightblue]
	1778093838960 -> 1778094028208
	1778094028208 [label=AccumulateGrad]
	1778094027728 -> 1778094027920
	1778094027728 [label=ConvolutionBackward0]
	1778094028640 -> 1778094027728
	1778094028640 [label=ReluBackward0]
	1778094028832 -> 1778094028640
	1778094028832 [label=ConvolutionBackward0]
	1778094276672 -> 1778094028832
	1778094276672 [label=AdaptiveMaxPool2DBackward0]
	1778094027152 -> 1778094276672
	1778094028928 -> 1778094028832
	1778094028208 -> 1778094027728
	1778094026960 -> 1778094026912
	1778094026960 [label=SigmoidBackward0]
	1778094027248 -> 1778094026960
	1778094027248 [label=ConvolutionBackward0]
	1778094028400 -> 1778094027248
	1778094028400 [label=CatBackward0]
	1778094292512 -> 1778094028400
	1778094292512 [label=MeanBackward1]
	1778094027008 -> 1778094292512
	1778094292704 -> 1778094028400
	1778094292704 [label=MaxBackward0]
	1778094027008 -> 1778094292704
	1778094029504 -> 1778094027248
	1778093839120 [label="decoder_attentions.2.1.conv.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	1778093839120 -> 1778094029504
	1778094029504 [label=AccumulateGrad]
	1778094026624 -> 1778094026480
	1778094026432 -> 1778094026288
	1778093839280 [label="decoder_blocks.3.0.weight
 (64, 192, 3, 3)" fillcolor=lightblue]
	1778093839280 -> 1778094026432
	1778094026432 [label=AccumulateGrad]
	1778094026384 -> 1778094026288
	1778093839360 [label="decoder_blocks.3.0.bias
 (64)" fillcolor=lightblue]
	1778093839360 -> 1778094026384
	1778094026384 [label=AccumulateGrad]
	1778094026240 -> 1778094026192
	1778093839440 [label="decoder_blocks.3.1.weight
 (64)" fillcolor=lightblue]
	1778093839440 -> 1778094026240
	1778094026240 [label=AccumulateGrad]
	1778094026096 -> 1778094026192
	1778093839520 [label="decoder_blocks.3.1.bias
 (64)" fillcolor=lightblue]
	1778093839520 -> 1778094026096
	1778094026096 [label=AccumulateGrad]
	1778094025952 -> 1778094025808
	1778093840000 [label="decoder_blocks.3.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1778093840000 -> 1778094025952
	1778094025952 [label=AccumulateGrad]
	1778094025904 -> 1778094025808
	1778093840080 [label="decoder_blocks.3.3.bias
 (64)" fillcolor=lightblue]
	1778093840080 -> 1778094025904
	1778094025904 [label=AccumulateGrad]
	1778094025760 -> 1778094025712
	1778093840160 [label="decoder_blocks.3.4.weight
 (64)" fillcolor=lightblue]
	1778093840160 -> 1778094025760
	1778094025760 [label=AccumulateGrad]
	1778094025616 -> 1778094025712
	1778093840240 [label="decoder_blocks.3.4.bias
 (64)" fillcolor=lightblue]
	1778093840240 -> 1778094025616
	1778094025616 [label=AccumulateGrad]
	1778094025472 -> 1778094025328
	1778093840720 [label="decoder_blocks.3.6.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1778093840720 -> 1778094025472
	1778094025472 [label=AccumulateGrad]
	1778094025424 -> 1778094025328
	1778093840800 [label="decoder_blocks.3.6.bias
 (64)" fillcolor=lightblue]
	1778093840800 -> 1778094025424
	1778094025424 [label=AccumulateGrad]
	1778094025280 -> 1778094025232
	1778093840880 [label="decoder_blocks.3.7.weight
 (64)" fillcolor=lightblue]
	1778093840880 -> 1778094025280
	1778094025280 [label=AccumulateGrad]
	1778094025136 -> 1778094025232
	1778093840960 [label="decoder_blocks.3.7.bias
 (64)" fillcolor=lightblue]
	1778093840960 -> 1778094025136
	1778094025136 [label=AccumulateGrad]
	1778094025040 -> 1778094024944
	1778094025040 [label=SigmoidBackward0]
	1778094025856 -> 1778094025040
	1778094025856 [label=AddBackward0]
	1778094025568 -> 1778094025856
	1778094025568 [label=ConvolutionBackward0]
	1778094026048 -> 1778094025568
	1778094026048 [label=ReluBackward0]
	1778094026528 -> 1778094026048
	1778094026528 [label=ConvolutionBackward0]
	1778094026720 -> 1778094026528
	1778094026720 [label=MeanBackward1]
	1778094025088 -> 1778094026720
	1778094026864 -> 1778094026528
	1778093841360 [label="decoder_attentions.3.0.mlp.0.weight
 (4, 64, 1, 1)" fillcolor=lightblue]
	1778093841360 -> 1778094026864
	1778094026864 [label=AccumulateGrad]
	1778094026144 -> 1778094025568
	1778093841520 [label="decoder_attentions.3.0.mlp.2.weight
 (64, 4, 1, 1)" fillcolor=lightblue]
	1778093841520 -> 1778094026144
	1778094026144 [label=AccumulateGrad]
	1778094025664 -> 1778094025856
	1778094025664 [label=ConvolutionBackward0]
	1778094026576 -> 1778094025664
	1778094026576 [label=ReluBackward0]
	1778094027440 -> 1778094026576
	1778094027440 [label=ConvolutionBackward0]
	1778094026336 -> 1778094027440
	1778094026336 [label=AdaptiveMaxPool2DBackward0]
	1778094025088 -> 1778094026336
	1778094026864 -> 1778094027440
	1778094026144 -> 1778094025664
	1778094024896 -> 1778094024848
	1778094024896 [label=SigmoidBackward0]
	1778094025184 -> 1778094024896
	1778094025184 [label=ConvolutionBackward0]
	1778094026768 -> 1778094025184
	1778094026768 [label=CatBackward0]
	1778094292656 -> 1778094026768
	1778094292656 [label=MeanBackward1]
	1778094024944 -> 1778094292656
	1778094292800 -> 1778094026768
	1778094292800 [label=MaxBackward0]
	1778094024944 -> 1778094292800
	1778094027056 -> 1778094025184
	1778093841680 [label="decoder_attentions.3.1.conv.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	1778093841680 -> 1778094027056
	1778094027056 [label=AccumulateGrad]
	1778094024560 -> 1778094024416
	1778094024368 -> 1778094024224
	1778093841840 [label="decoder_blocks.4.0.weight
 (32, 96, 3, 3)" fillcolor=lightblue]
	1778093841840 -> 1778094024368
	1778094024368 [label=AccumulateGrad]
	1778094024320 -> 1778094024224
	1778093841920 [label="decoder_blocks.4.0.bias
 (32)" fillcolor=lightblue]
	1778093841920 -> 1778094024320
	1778094024320 [label=AccumulateGrad]
	1778094024176 -> 1778094024128
	1778093842000 [label="decoder_blocks.4.1.weight
 (32)" fillcolor=lightblue]
	1778093842000 -> 1778094024176
	1778094024176 [label=AccumulateGrad]
	1778094024032 -> 1778094024128
	1778093842080 [label="decoder_blocks.4.1.bias
 (32)" fillcolor=lightblue]
	1778093842080 -> 1778094024032
	1778094024032 [label=AccumulateGrad]
	1778094023888 -> 1778094023744
	1778093842560 [label="decoder_blocks.4.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1778093842560 -> 1778094023888
	1778094023888 [label=AccumulateGrad]
	1778094023840 -> 1778094023744
	1778093842640 [label="decoder_blocks.4.3.bias
 (32)" fillcolor=lightblue]
	1778093842640 -> 1778094023840
	1778094023840 [label=AccumulateGrad]
	1778094023696 -> 1778094023648
	1778093842720 [label="decoder_blocks.4.4.weight
 (32)" fillcolor=lightblue]
	1778093842720 -> 1778094023696
	1778094023696 [label=AccumulateGrad]
	1778094023552 -> 1778094023648
	1778093842800 [label="decoder_blocks.4.4.bias
 (32)" fillcolor=lightblue]
	1778093842800 -> 1778094023552
	1778094023552 [label=AccumulateGrad]
	1778094023408 -> 1778094023264
	1778093843280 [label="decoder_blocks.4.6.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1778093843280 -> 1778094023408
	1778094023408 [label=AccumulateGrad]
	1778094023360 -> 1778094023264
	1778093843360 [label="decoder_blocks.4.6.bias
 (32)" fillcolor=lightblue]
	1778093843360 -> 1778094023360
	1778094023360 [label=AccumulateGrad]
	1778094023216 -> 1778094023168
	1778093843440 [label="decoder_blocks.4.7.weight
 (32)" fillcolor=lightblue]
	1778093843440 -> 1778094023216
	1778094023216 [label=AccumulateGrad]
	1778094023072 -> 1778094023168
	1778093843520 [label="decoder_blocks.4.7.bias
 (32)" fillcolor=lightblue]
	1778093843520 -> 1778094023072
	1778094023072 [label=AccumulateGrad]
	1778094022976 -> 1778094022880
	1778094022976 [label=SigmoidBackward0]
	1778094023792 -> 1778094022976
	1778094023792 [label=AddBackward0]
	1778094023504 -> 1778094023792
	1778094023504 [label=ConvolutionBackward0]
	1778094023984 -> 1778094023504
	1778094023984 [label=ReluBackward0]
	1778094024464 -> 1778094023984
	1778094024464 [label=ConvolutionBackward0]
	1778094024656 -> 1778094024464
	1778094024656 [label=MeanBackward1]
	1778094023024 -> 1778094024656
	1778094024800 -> 1778094024464
	1778093844000 [label="decoder_attentions.4.0.mlp.0.weight
 (2, 32, 1, 1)" fillcolor=lightblue]
	1778093844000 -> 1778094024800
	1778094024800 [label=AccumulateGrad]
	1778094024080 -> 1778094023504
	1778093844160 [label="decoder_attentions.4.0.mlp.2.weight
 (32, 2, 1, 1)" fillcolor=lightblue]
	1778093844160 -> 1778094024080
	1778094024080 [label=AccumulateGrad]
	1778094023600 -> 1778094023792
	1778094023600 [label=ConvolutionBackward0]
	1778094024512 -> 1778094023600
	1778094024512 [label=ReluBackward0]
	1778094025376 -> 1778094024512
	1778094025376 [label=ConvolutionBackward0]
	1778094024272 -> 1778094025376
	1778094024272 [label=AdaptiveMaxPool2DBackward0]
	1778094023024 -> 1778094024272
	1778094024800 -> 1778094025376
	1778094024080 -> 1778094023600
	1778094022832 -> 1778094022688
	1778094022832 [label=SigmoidBackward0]
	1778094023120 -> 1778094022832
	1778094023120 [label=ConvolutionBackward0]
	1778094024704 -> 1778094023120
	1778094024704 [label=CatBackward0]
	1778094278496 -> 1778094024704
	1778094278496 [label=MeanBackward1]
	1778094022880 -> 1778094278496
	1778094292896 -> 1778094024704
	1778094292896 [label=MaxBackward0]
	1778094022880 -> 1778094292896
	1778094024992 -> 1778094023120
	1778093844320 [label="decoder_attentions.4.1.conv.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	1778093844320 -> 1778094024992
	1778094024992 [label=AccumulateGrad]
	1778094022640 -> 1778094022496
	1778093844480 [label="dilation_block.0.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1778093844480 -> 1778094022640
	1778094022640 [label=AccumulateGrad]
	1778094022592 -> 1778094022496
	1778093844560 [label="dilation_block.0.bias
 (32)" fillcolor=lightblue]
	1778093844560 -> 1778094022592
	1778094022592 [label=AccumulateGrad]
	1778094022448 -> 1778094022400
	1778093844640 [label="dilation_block.1.weight
 (32)" fillcolor=lightblue]
	1778093844640 -> 1778094022448
	1778094022448 [label=AccumulateGrad]
	1778094022304 -> 1778094022400
	1778093844720 [label="dilation_block.1.bias
 (32)" fillcolor=lightblue]
	1778093844720 -> 1778094022304
	1778094022304 [label=AccumulateGrad]
	1778094022160 -> 1778094022016
	1778093845200 [label="dilation_block.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1778093845200 -> 1778094022160
	1778094022160 [label=AccumulateGrad]
	1778094022112 -> 1778094022016
	1778093845280 [label="dilation_block.3.bias
 (32)" fillcolor=lightblue]
	1778093845280 -> 1778094022112
	1778094022112 [label=AccumulateGrad]
	1778094021968 -> 1778094021920
	1778093845360 [label="dilation_block.4.weight
 (32)" fillcolor=lightblue]
	1778093845360 -> 1778094021968
	1778094021968 [label=AccumulateGrad]
	1778094021824 -> 1778094021920
	1778093845440 [label="dilation_block.4.bias
 (32)" fillcolor=lightblue]
	1778093845440 -> 1778094021824
	1778094021824 [label=AccumulateGrad]
	1778094021680 -> 1778094021536
	1778093845920 [label="dilation_block.6.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1778093845920 -> 1778094021680
	1778094021680 [label=AccumulateGrad]
	1778094021632 -> 1778094021536
	1778093846000 [label="dilation_block.6.bias
 (32)" fillcolor=lightblue]
	1778093846000 -> 1778094021632
	1778094021632 [label=AccumulateGrad]
	1778094021488 -> 1778094021440
	1778093846080 [label="dilation_block.7.weight
 (32)" fillcolor=lightblue]
	1778093846080 -> 1778094021488
	1778094021488 [label=AccumulateGrad]
	1778094021344 -> 1778094021440
	1778093846160 [label="dilation_block.7.bias
 (32)" fillcolor=lightblue]
	1778093846160 -> 1778094021344
	1778094021344 [label=AccumulateGrad]
	1778094021248 -> 1778094021200
	1778094021248 [label=SigmoidBackward0]
	1778094022064 -> 1778094021248
	1778094022064 [label=AddBackward0]
	1778094021776 -> 1778094022064
	1778094021776 [label=ConvolutionBackward0]
	1778094022256 -> 1778094021776
	1778094022256 [label=ReluBackward0]
	1778094022736 -> 1778094022256
	1778094022736 [label=ConvolutionBackward0]
	1778094022928 -> 1778094022736
	1778094022928 [label=MeanBackward1]
	1778094021296 -> 1778094022928
	1778094023312 -> 1778094022736
	1778093846640 [label="final_attention.0.mlp.0.weight
 (2, 32, 1, 1)" fillcolor=lightblue]
	1778093846640 -> 1778094023312
	1778094023312 [label=AccumulateGrad]
	1778094022352 -> 1778094021776
	1778093846800 [label="final_attention.0.mlp.2.weight
 (32, 2, 1, 1)" fillcolor=lightblue]
	1778093846800 -> 1778094022352
	1778094022352 [label=AccumulateGrad]
	1778094021872 -> 1778094022064
	1778094021872 [label=ConvolutionBackward0]
	1778094022784 -> 1778094021872
	1778094022784 [label=ReluBackward0]
	1778094292848 -> 1778094022784
	1778094292848 [label=ConvolutionBackward0]
	1778094292752 -> 1778094292848
	1778094292752 [label=AdaptiveMaxPool2DBackward0]
	1778094021296 -> 1778094292752
	1778094023312 -> 1778094292848
	1778094022352 -> 1778094021872
	1778094021008 -> 1778094020960
	1778094021008 [label=SigmoidBackward0]
	1778094021584 -> 1778094021008
	1778094021584 [label=ConvolutionBackward0]
	1778094022544 -> 1778094021584
	1778094022544 [label=CatBackward0]
	1778094292944 -> 1778094022544
	1778094292944 [label=MeanBackward1]
	1778094021056 -> 1778094292944
	1778094407888 -> 1778094022544
	1778094407888 [label=MaxBackward0]
	1778094021056 -> 1778094407888
	1778094021392 -> 1778094021584
	1778093847040 [label="final_attention.2.conv.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	1778093847040 -> 1778094021392
	1778094021392 [label=AccumulateGrad]
	1778094020720 -> 1778094020576
	1778093847200 [label="flow_branch.0.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1778093847200 -> 1778094020720
	1778094020720 [label=AccumulateGrad]
	1778094020672 -> 1778094020576
	1778093847280 [label="flow_branch.0.bias
 (32)" fillcolor=lightblue]
	1778093847280 -> 1778094020672
	1778094020672 [label=AccumulateGrad]
	1778094020528 -> 1778094020480
	1778093847360 [label="flow_branch.1.weight
 (32)" fillcolor=lightblue]
	1778093847360 -> 1778094020528
	1778094020528 [label=AccumulateGrad]
	1778094020384 -> 1778094020480
	1778093847440 [label="flow_branch.1.bias
 (32)" fillcolor=lightblue]
	1778093847440 -> 1778094020384
	1778094020384 [label=AccumulateGrad]
	1778094020240 -> 1778094019952
	1778093847920 [label="flow_branch.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1778093847920 -> 1778094020240
	1778094020240 [label=AccumulateGrad]
	1778094020192 -> 1778094019952
	1778093848000 [label="flow_branch.3.bias
 (32)" fillcolor=lightblue]
	1778093848000 -> 1778094020192
	1778094020192 [label=AccumulateGrad]
	1778094020048 -> 1778094020096
	1778093848080 [label="flow_branch.4.weight
 (32)" fillcolor=lightblue]
	1778093848080 -> 1778094020048
	1778094020048 [label=AccumulateGrad]
	1778094020000 -> 1778094020096
	1778093848160 [label="flow_branch.4.bias
 (32)" fillcolor=lightblue]
	1778093848160 -> 1778094020000
	1778094020000 [label=AccumulateGrad]
	1778094019808 -> 1778094019856
	1778093848640 [label="flow_branch.6.weight
 (1, 32, 1, 1)" fillcolor=lightblue]
	1778093848640 -> 1778094019808
	1778094019808 [label=AccumulateGrad]
	1778094019904 -> 1778094019856
	1778093848720 [label="flow_branch.6.bias
 (1)" fillcolor=lightblue]
	1778093848720 -> 1778094019904
	1778094019904 [label=AccumulateGrad]
	1778094019856 -> 1778094214672
	1778094215072 [label="
 (1, 1, 256, 256)" fillcolor=darkolivegreen1]
	1778094020144 [label=ConvolutionBackward0]
	1778094019712 -> 1778094020144
	1778094019712 [label=ReluBackward0]
	1778094020912 -> 1778094019712
	1778094020912 [label=NativeBatchNormBackward0]
	1778094021104 -> 1778094020912
	1778094021104 [label=ConvolutionBackward0]
	1778094407792 -> 1778094021104
	1778094407792 [label=ReluBackward0]
	1778094408080 -> 1778094407792
	1778094408080 [label=NativeBatchNormBackward0]
	1778094408176 -> 1778094408080
	1778094408176 [label=ConvolutionBackward0]
	1778094020768 -> 1778094408176
	1778094408368 -> 1778094408176
	1778093848880 [label="noise_branch.0.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1778093848880 -> 1778094408368
	1778094408368 [label=AccumulateGrad]
	1778094408320 -> 1778094408176
	1778093848960 [label="noise_branch.0.bias
 (32)" fillcolor=lightblue]
	1778093848960 -> 1778094408320
	1778094408320 [label=AccumulateGrad]
	1778094408128 -> 1778094408080
	1778093849040 [label="noise_branch.1.weight
 (32)" fillcolor=lightblue]
	1778093849040 -> 1778094408128
	1778094408128 [label=AccumulateGrad]
	1778094407984 -> 1778094408080
	1778093849120 [label="noise_branch.1.bias
 (32)" fillcolor=lightblue]
	1778093849120 -> 1778094407984
	1778094407984 [label=AccumulateGrad]
	1778094407840 -> 1778094021104
	1778093849600 [label="noise_branch.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1778093849600 -> 1778094407840
	1778094407840 [label=AccumulateGrad]
	1778094407744 -> 1778094021104
	1778093849680 [label="noise_branch.3.bias
 (32)" fillcolor=lightblue]
	1778093849680 -> 1778094407744
	1778094407744 [label=AccumulateGrad]
	1778094020816 -> 1778094020912
	1778093849760 [label="noise_branch.4.weight
 (32)" fillcolor=lightblue]
	1778093849760 -> 1778094020816
	1778094020816 [label=AccumulateGrad]
	1778094020336 -> 1778094020912
	1778093849840 [label="noise_branch.4.bias
 (32)" fillcolor=lightblue]
	1778093849840 -> 1778094020336
	1778094020336 [label=AccumulateGrad]
	1778094019760 -> 1778094020144
	1778093850320 [label="noise_branch.6.weight
 (1, 32, 1, 1)" fillcolor=lightblue]
	1778093850320 -> 1778094019760
	1778094019760 [label=AccumulateGrad]
	1778094020624 -> 1778094020144
	1778093850400 [label="noise_branch.6.bias
 (1)" fillcolor=lightblue]
	1778093850400 -> 1778094020624
	1778094020624 [label=AccumulateGrad]
	1778094020144 -> 1778094215072
}
